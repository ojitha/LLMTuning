{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1DsiaMBwbo/ddshaoY+zp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "layout: post\n",
        "title: LLM Tuning\n",
        "date:   2025-09-18\n",
        "categories: [Python]\n",
        "mermaid: true\n",
        "typora-root-url: /Users/ojitha/GitHub/ojitha.github.io\n",
        "typora-copy-images-to: ../../blog/assets/images/${filename}\n",
        "---"
      ],
      "metadata": {
        "id": "NTRURJivpVLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder and Decoder\n",
        "A transformer is built on an encoder-decoder architecture, where the encoder takes in input and outputs a matrix representation of that input. The decoder iteratively generates output using that representation. Transformer[^1] relies on self-attention to model the relationship between tokens in a sentence.\n",
        "\n",
        "![Transformer](https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Transformer%2C_full_architecture.png/500px-Transformer%2C_full_architecture.png)\n",
        "\n",
        "- Transformer Encoder:\n",
        "  - Processes input sequence all at once (parallel processing)\n",
        "  - Uses self-attention to understand relationships between all words\n",
        "  - Output: Rich contextual representations of input\n",
        "- Transformer Decoder:\n",
        "  - Generates output sequence one token at a time (autoregressive)\n",
        "  - Uses self-attention + cross-attention to input encoder representations\n",
        "  - Output: Generated sequence (translation, text generation, etc.)\n",
        "\n",
        "There are 2 types of models:\n",
        "1. Auto-Regressive Models:\n",
        "  - What: Predict next token based on previous tokens\n",
        "  - Training: Learn $P(x_t | x_1, x_2, ..., x_{t-1})$\n",
        "  - Direction: Left-to-right (forward prediction)\n",
        "  - Examples: GPT, Claude, traditional language models\n",
        "  - Use cases: Text generation, completion, dialogue\n",
        "```\n",
        "Input:  \"The cat sat on\" → Predict: \"the\"\n",
        "```\n",
        "2. Auto-Encoding Models:\n",
        "  - What: Reconstruct corrupted/masked input\n",
        "  - Training: Learn to fill in missing pieces from context\n",
        "  - Direction: Bidirectional (sees both left and right context)\n",
        "  - Examples: BERT, RoBERTa, DeBERTa\n",
        "  - Use cases: Text understanding, classification, Q&A  \n",
        "```\n",
        "Input:  \"The [MASK] sat on mat\" → Predict: \"cat\"\n",
        "```\n",
        "\n",
        "Self-Attention: Each word \"looks at\" all other words to understand context and relationships.  \n",
        "\n",
        "![Autoregressive Models](/../blog/assets/images/2025_09_18_LLMTuningWithPyTorch/autoregressive_models.svg)\n",
        "\n",
        "> GPT and BERT are Transformers, but they are different language models.\n",
        "{:.info-box}"
      ],
      "metadata": {
        "id": "7OtQfyB3iSZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attenstion\n",
        "Standard attention calculated using 3 matrices:\n",
        "\n",
        "1. query\n",
        "2. key\n",
        "3. value"
      ],
      "metadata": {
        "id": "YcHJNsb387kg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_SQzSzESNzwj"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-dimensional tensor"
      ],
      "metadata": {
        "id": "2f7FClZVPajj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_d_tensor = torch.LongTensor([0])\n",
        "print(f'Shape of {one_d_tensor} is {one_d_tensor.shape} and dimension is {one_d_tensor.dim()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gochs8VPRwI",
        "outputId": "47f1501f-3e0f-48f1-fa77-779da9eabfe0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor([0]) is torch.Size([1]) and dimension is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_d_tensor = torch.LongTensor([0,1,2])\n",
        "print(f'Shape of {one_d_tensor} is {one_d_tensor.shape} and dimension is {one_d_tensor.dim()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb-BqznJP7M3",
        "outputId": "ae017224-3ce4-48ba-e6ff-ea4471a7dffc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor([0, 1, 2]) is torch.Size([3]) and dimension is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_d_tensor = torch.LongTensor([[0,1,2],[3,4,5]])\n",
        "print(two_d_tensor.shape)\n",
        "print(f'Shape of {two_d_tensor} is {two_d_tensor.shape} and dimension is {two_d_tensor.dim()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihnENyH6QIlH",
        "outputId": "aad6ecb2-daea-44fd-e93a-f5a4205726f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "Shape of tensor([[0, 1, 2],\n",
            "        [3, 4, 5]]) is torch.Size([2, 3]) and dimension is 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_d_tensor = torch.LongTensor([0,1,2])\n",
        "two_d_tensor = one_d_tensor.unsqueeze(0)\n",
        "print(f'Shape of {two_d_tensor} is {two_d_tensor.shape} and dimension is {two_d_tensor.dim()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T37Nag_Qt-K",
        "outputId": "a458fc78-662e-43d3-fc14-52b5fe063ee3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor([[0, 1, 2]]) is torch.Size([1, 3]) and dimension is 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_d_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUP1VxwrSNUO",
        "outputId": "11f29bff-c12c-495f-8870-9a8073d2d252"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_d_tensor.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSxmSdRRSx1L",
        "outputId": "299c7629-74c4-423b-fbe0-b2f1240f9430"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [2]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[^1]: [Attetnsion All You need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf){:target=\"_blank\"}\n",
        "\n",
        "\n",
        "{:gtxt: .message color=\"green\"}\n",
        "\n",
        "{:ytxt: .message color=\"yellow\"}\n",
        "\n",
        "{:rtxt: .message color=\"red\"}"
      ],
      "metadata": {
        "id": "qgbG4HwY7GNm"
      }
    }
  ]
}